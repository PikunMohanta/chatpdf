# PDFPixie - AI-Powered PDF Chat Application ğŸ¤–ğŸ“„

Your intelligent PDF companion. Upload PDFs, ask questions, and get AI-powered responses based on document content using advanced semantic search and real-time chat.

## âœ¨ Features

- ğŸ“„ **PDF Upload & Processing** - Drag-and-drop interface with instant text extraction
- ğŸ¤– **AI-Powered Chat** - Interactive conversations with your PDF documents
- ğŸ” **Semantic Search** - ChromaDB vector embeddings for accurate context retrieval
- âš¡ **Real-time Communication** - WebSocket-based chat with typing indicators
- ï¿½ **Chat History** - Persistent conversation storage with session management
- ğŸ¨ **Modern UI** - Beautiful interface with glassmorphism effects and Zen Serif font
- ğŸš€ **Fast Development** - UV package manager for 10-100x faster installations

## ğŸ› ï¸ Tech Stack

**Frontend:**
- React 18 + TypeScript
- Socket.IO Client (real-time communication)
- React-PDF (document preview)
- Vite (build tool)
- CSS3 with custom design system

**Backend:**
- FastAPI (async Python web framework)
- Socket.IO Server (WebSocket communication)
- LangChain (AI orchestration)
- ChromaDB (vector embeddings)
- PyMuPDF (PDF text extraction)
- OpenRouter API (AI responses)
- SQLite (chat history storage)

**Development:**
- UV Package Manager (faster than pip)
- Docker & Docker Compose (containerization)
- Python 3.10+
- Node.js 18+

## ğŸš€ Quick Start

### Prerequisites

Before you begin, ensure you have:
- **Node.js 18+** - [Download](https://nodejs.org/)
- **Python 3.10+** - [Download](https://python.org/)
- **Git** - [Download](https://git-scm.com/)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/chatpdf.git
cd chatpdf
```

2. **Backend Setup**

```bash
cd backend

# Install UV package manager (optional but recommended - 10-100x faster)
# Windows PowerShell:
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
# Unix/macOS:
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment
python -m venv .venv
# Or with UV:
uv venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# Unix/macOS:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
# Or with UV (much faster):
uv pip install -r requirements.txt
```

3. **Frontend Setup**

```bash
cd frontend
npm install
```

### Running the Application

You need **two terminals** - one for backend, one for frontend:

**Terminal 1 - Backend:**
```bash
cd backend
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Unix/macOS

# IMPORTANT: Must use 'socket_app' for chat to work!
uvicorn main:socket_app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm start
```

### Access the Application

- ğŸŒ **Frontend**: http://localhost:3000
- ğŸ”Œ **Backend API**: http://localhost:8000
- ğŸ“š **API Documentation**: http://localhost:8000/docs

## ğŸ“– How to Use

1. **Upload a PDF**
   - Click "Upload PDF" or drag-and-drop a PDF file
   - Wait for processing to complete (text extraction + embeddings)

2. **Start Chatting**
   - Type your question in the chat input
   - Press Enter or click Send
   - AI will analyze the document and respond with relevant information

3. **View Chat History**
   - Previous conversations are automatically saved
   - Switch between different PDF sessions from the sidebar

4. **Search Modes**
   - Automatic semantic search finds relevant document sections
   - Context-aware AI responses based on document content

## ğŸ“ Project Structure

```
chatpdf/
â”œâ”€â”€ frontend/                 # React TypeScript application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Main app component
â”‚   â”‚   â””â”€â”€ main.tsx         # Entry point
â”‚   â”œâ”€â”€ index.html           # HTML template (includes Zen Serif font)
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                 # FastAPI Python application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ auth.py          # Authentication logic
â”‚   â”‚   â”œâ”€â”€ pdf_processing.py # PDF parsing & embeddings
â”‚   â”‚   â”œâ”€â”€ chat.py          # Chat & AI response generation
â”‚   â”‚   â”œâ”€â”€ chat_history_db.py # Chat history management
â”‚   â”‚   â””â”€â”€ openrouter_client.py # AI client
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ uploads/         # Uploaded PDFs
â”‚   â”‚   â”œâ”€â”€ chromadb/        # Vector embeddings
â”‚   â”‚   â””â”€â”€ chat_history/    # SQLite chat database
â”‚   â”œâ”€â”€ main.py              # FastAPI app + Socket.IO
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docker/                  # Docker configurations
â”œâ”€â”€ scripts/                 # Setup scripts
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

### Environment Variables (Optional)

Create `.env` file in `backend/` directory:

```env
# AI Configuration (optional - uses defaults if not set)
OPENROUTER_API_KEY=your-api-key-here
OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Storage paths (auto-created)
UPLOAD_DIR=./data/uploads
CHROMA_DIR=./data/chromadb
CHAT_HISTORY_DIR=./data/chat_history
```

The application works in **development mode** without any API keys:
- âœ… Local file storage for PDFs
- âœ… ChromaDB for local embeddings
- âœ… SQLite for chat history
- âœ… Mock authentication for development

## ğŸ§ª Development

### Key Commands

```bash
# Backend
cd backend
uvicorn main:socket_app --reload    # Start with hot reload
pytest tests/                       # Run tests (if available)

# Frontend
cd frontend
npm run dev                         # Start dev server
npm run build                       # Build for production
npm run preview                     # Preview production build
```

### Important Notes

- âš ï¸ **Must use `main:socket_app`** - Using `main:app` will break Socket.IO chat!
- ğŸ’¡ Frontend runs on port 3000 (not 3001)
- ğŸ”„ Backend uses async Socket.IO for real-time communication
- ğŸ’¾ Chat history automatically persists to SQLite database

## ğŸ³ Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up --build

# Or use development compose file
docker-compose -f docker-compose.dev.yml up
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- FastAPI for the excellent Python web framework
- React team for the powerful UI library
- LangChain for AI orchestration tools
- ChromaDB for vector embeddings
- OpenRouter for AI API access

---

**Made with â¤ï¸ for intelligent document interaction**